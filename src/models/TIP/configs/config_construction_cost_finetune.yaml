# TIP Fine-Tuning Config for Construction Cost Regression
# Stage 2: Supervised Fine-Tuning

defaults:
  - _self_

# Configure Hydra to use work_dir in project root instead of outputs
hydra:
  run:
    dir: ${data_base}/work_dir/hydra/${now:%Y-%m-%d}/${now:%H-%M-%S}
  output_subdir: null  # Don't create outputs subdirectory

# Task
datatype: multimodal  # Required by run.py (used for checkpoint path)
eval_datatype: multimodal
strategy: tip
task: regression
use_construction_cost_dataset: true
algorithm_name: TIP  # Required by run.py
target: construction_cost  # Required by run.py (for logging and exp name)

# Base directory for data paths (project root)
data_base: /hdd/hiep/CODE/Construction_Cost_Prediction

# Checkpoint from pretraining
checkpoint: /hdd/hiep/CODE/Construction_Cost_Prediction/work_dir/runs/pretrain/QueryAttentionRegression_1223_1951/checkpoint_best_rmsle_99_0.2495.ckpt

# Data paths (absolute paths)
# Note: For fine-tuning, we need ground truth, so we use train/val splits (NOT test set)

# K-Fold Cross-Validation Options
use_kfold: False  # If true, use k-fold CV from unified trainval.csv; if false, use fixed train/val splits
k_fold: 5  # Number of folds (only used if use_kfold=true)
k_fold_seed: 42  # Random seed for k-fold splitting (only used if use_kfold=true)
k_fold_current: -1  # Current fold to use (0-indexed, 0 to k_fold-1). Set to -1 (default) to run all folds automatically (only used if use_kfold=true)
data_trainval_tabular: /hdd/hiep/CODE/Construction_Cost_Prediction/data/annotation/trainval/trainval_clean.csv  # Unified trainval CSV (preprocessed, only used if use_kfold=true)

# Fixed Split Options (only used if use_kfold=false)
# data_train_eval_tabular: /hdd/hiep/CODE/Construction_Cost_Prediction/data/annotation/train/train_clean.csv
data_train_eval_tabular: /hdd/hiep/CODE/Construction_Cost_Prediction/data/annotation/trainval/trainval_clean.csv
data_val_eval_tabular: /hdd/hiep/CODE/Construction_Cost_Prediction/data/annotation/val/val_clean.csv  # Val split (has ground truth)
# train_metadata_path: /hdd/hiep/CODE/Construction_Cost_Prediction/data/annotation/train/train_clean_metadata.pkl
train_metadata_path: /hdd/hiep/CODE/Construction_Cost_Prediction/data/annotation/train/trainval_clean_metadata.pkl
val_metadata_path: /hdd/hiep/CODE/Construction_Cost_Prediction/data/annotation/val/val_clean_metadata.pkl

# Common paths (used for both k-fold and fixed split)
composite_dir_trainval: /hdd/hiep/CODE/Construction_Cost_Prediction/data/trainval_composite  # For train/val sets (both use this)
composite_dir_test: /hdd/hiep/CODE/Construction_Cost_Prediction/data/test_composite  # For test set (only for final inference, no training)
field_lengths_tabular: /hdd/hiep/CODE/Construction_Cost_Prediction/data/annotation/field_lengths.pt
trainval_metadata_path: /hdd/hiep/CODE/Construction_Cost_Prediction/data/annotation/trainval/trainval_clean_metadata.pkl  # Metadata for unified trainval (used if use_kfold=true)
labels_train_eval_imaging: null  # Not needed for fine-tuning - targets are in CSV file
labels_val_eval_imaging: null  # Not needed for fine-tuning - targets are in CSV file

# Model (inherited from checkpoint)
use_satellite_encoder: true
use_satlas: true
sentinel2_model_id: Sentinel2_SwinB_SI_MS
satellite_feature_dim: 512

# Fine-Tuning Strategy
finetune_strategy: frozen  # Freeze entire pretrained backbone (image + tabular + multimodal encoders)
freeze_image: true  # Freeze image encoder (redundant if finetune_strategy=frozen, but kept for clarity)
freeze_tabular: true  # Freeze tabular encoder (redundant if finetune_strategy=frozen, but kept for clarity)
missing_tabular: false
# Note: Only the regression head (classifier) will be trained when finetune_strategy=frozen

# Alternative: Unfreeze backbone for better convergence (commented out - can enable in future)
# finetune_strategy: trainable  # Unfreeze backbone with lower LR for better convergence
# freeze_image: true  # Keep image encoder frozen (already well-pretrained)
# freeze_tabular: false  # Unfreeze tabular encoder (adapt to new head)
# Note: When finetune_strategy='trainable':
#   - Multimodal encoder: lr_finetune (5e-5)
#   - Tabular encoder: lr_finetune (5e-5) if freeze_tabular=false
#   - Image encoder: frozen (freeze_image=true)
#   - Regression head: lr_finetune * 5 (2.5e-4)

# Regression Head
num_classes: 1
# Regression Head Configuration (all head-related parameters in one dict)
# regression_head:
#   type: AttentionAggregationRegression  # Head class: RegressionMLP or AttentionAggregationRegression
#   p: 0.2  # Dropout probability
#   n_hidden: null  # Hidden dimension (null = use n_input, which is embedding_dim)
#   num_heads: 8  # Number of attention heads (for AttentionAggregationRegression)
#   # Loss configuration (dict with loss names and weights)
#   # Only losses in this dict will contribute to the total weighted loss for backprop
#   # All losses (rmsle, mae, rmse, mse, huber) are calculated internally for monitoring
#   loss_type:
#     rmsle: 1.0  # Primary metric (competition)
#     # mae: 0.2    # Interpretable error
#     # mse: 0.2    # Penalize large errors
#     # rmse: 0.1   # Root mean squared error
#   target_mean: 6.513477  # From preprocessing (log space) - must match pretrain config
#   target_std: 1.101045   # From preprocessing (log space) - must match pretrain config
#   target_log_transform: true
#   huber_delta: 1.0  # Delta parameter for Huber loss
#   # MoE-specific parameters (commented out - not used with AttentionAggregationRegression):
#   # num_experts: 4  # Number of expert networks (reduced from 8 for better convergence with small dataset)
#   # top_k: 2  # Top-K routing: number of experts to use per sample
#   # use_load_balancing: false  # Enable load balancing loss
#   # load_balancing_weight: 0.01  # Weight for load balancing loss


# regression_head:
#   type: MixtureOfExpertsRegression  # Head class: RegressionMLP or MixtureOfExpertsRegression
#   p: 0.2  # Dropout probability
#   n_hidden: 2048  # Hidden dimension (null = use n_input, which is embedding_dim)
#   # Loss configuration (dict with loss names and weights)
#   # Only losses in this dict will contribute to the total weighted loss for backprop
#   # All losses (rmsle, mae, rmse, mse, huber) are calculated internally for monitoring
#   loss_type:
#     rmsle: 1.0  # Primary metric (competition)
#     # mae: 0.2    # Interpretable error
#     # mse: 0.2    # Penalize large errors
#     # rmse: 0.1   # Root mean squared error
#   target_mean: 6.513477  # From preprocessing (log space) - must match pretrain config
#   target_std: 1.101045   # From preprocessing (log space) - must match pretrain config
#   target_log_transform: true
#   huber_delta: 1.0  # Delta parameter for Huber loss
#   # MoE-specific parameters:
#   num_experts: 4  # Number of expert networks (reduced from 8 for better convergence with small dataset)
#   top_k: 2  # Top-K routing: number of experts to use per sample
#   use_load_balancing: false  # Enable load balancing loss
#   load_balancing_weight: 0.01  # Weight for load balancing loss


# regression_head:
#   type: RegressionMLP  # Head class name: RegressionMLP or MixtureOfExpertsRegression
#   p: 0.2  # Dropout probability
#   n_hidden: null  # Hidden dimension (null = use n_input, which is embedding_dim)
#   # Loss configuration (dict with loss names and weights)
#   # Only losses in this dict will contribute to the total weighted loss for backprop
#   # All losses (rmsle, mae, rmse, mse, huber) are calculated internally for monitoring
#   loss_type:
#     rmsle: 1.0  # Primary metric (competition)
#     # mae: 0.2    # Interpretable error
#     # mse: 0.2    # Penalize large errors
#     # rmse: 0.1   # Root mean squared error
#   target_mean: 6.513477  # Mean of log(1 + target) values (computed from training dataset)
#   target_std: 1.101045   # Std of log(1 + target) values (computed from training dataset)
#   target_log_transform: true  # Whether targets are log-transformed (log1p)
#   huber_delta: 1.0  # Delta parameter for Huber loss


# regression_head:
#   type: AttentionAggregationRegression  # Head class: RegressionMLP or AttentionAggregationRegression
#   p: 0.2  # Dropout probability
#   n_hidden: 2048  # Hidden dimension (null = use n_input, which is embedding_dim)
#   num_heads: 8  # Number of attention heads (for AttentionAggregationRegression)
#   # Loss configuration (dict with loss names and weights)
#   # Only losses in this dict will contribute to the total weighted loss for backprop
#   # All losses (rmsle, mae, rmse, mse, huber) are calculated internally for monitoring
#   loss_type:
#     rmsle: 1.0  # Primary metric (competition)
#     # mae: 0.2    # Interpretable error
#     # mse: 0.2    # Penalize large errors
#     # rmse: 0.1   # Root mean squared error
#   target_mean: 6.513477  # From preprocessing (log space) - must match pretrain config
#   target_std: 1.101045   # From preprocessing (log space) - must match pretrain config
#   target_log_transform: true
#   huber_delta: 1.0  # Delta parameter for Huber loss

# Example alternatives (commented out — enable one at a time when testing new heads)
# regression_head:
#   type: QueryAttentionRegression
#   p: 0.2
#   n_hidden: 2048
#   num_queries: 1      # learnable queries (1–4 typical)
#   num_heads: 8        # attention heads for query pooling
#   loss_type:
#     rmsle: 1.0
#   target_mean: 6.513477
#   target_std: 1.101045
#   target_log_transform: true
#   huber_delta: 1.0

regression_head:
  type: MultiTaskCountryAwareRegression
  p: 0.2
  n_hidden: 2048
  num_queries: 1      # learnable queries (1–4 typical)
  num_heads: 8        # attention heads for query pooling
  loss_type:
    rmsle:
      self_weight: 1.0  # Weight to multiply raw loss (for normalization, user manually tunes)
      global_weight: 0.2  # Weight for contribution to total loss (percentage/contribution)
    classification_ce:  # Classification loss (same format as other losses)
      self_weight: 1.0  # Weight to multiply raw loss (for normalization, user manually tunes)
      global_weight: 0.2  # Weight for contribution to total loss (percentage/contribution)
  
  # Country-specific target statistics (if provided, enables country-specific normalization)
  # Format: {country_id: value} where country_id is 0 or 1
  target_mean_by_country:
    0: 7.478149  # Mean of log(1 + target) for country 0
    1: 5.304986  # Mean of log(1 + target) for country 1
  target_std_by_country:
    0: 0.138897  # Std of log(1 + target) for country 0
    1: 0.283889  # Std of log(1 + target) for country 1
  
  huber_delta: 1.0


# Training
batch_size: 32
lr: 3e-4  # Pretrain LR (not used in fine-tuning, but required by run.py)
weight_decay: 1e-5  # Pretrain weight decay (not used in fine-tuning, but required by run.py)
lr_finetune: 1e-4  # Fine-tuning learning rate (reduced from 1e-4 for better convergence)
weight_decay_finetune: 1e-5  # Fine-tuning weight decay
regressor_lr_multiplier: 1.0  # Multiplier for regression head LR (reduced from 10.0 to 5.0 for better convergence)
max_epochs: 200
log_every_n_steps: 1  # Log every step (since we have small number of batches ~13)

# Scheduler (same as pretraining for consistency)
scheduler: anneal  # Options: anneal (LinearWarmupCosineAnnealingLR), plateau (ReduceLROnPlateau)
warmup_epochs: 20  # Warmup epochs (increased from 10 for better stability when training from scratch)
anneal_max_epochs: ${max_epochs}  # Max epochs for anneal scheduler (usually same as max_epochs)

# Plateau scheduler
# scheduler: plateau
# plateau_factor: 0.5
# plateau_patience: 6        # Wait 6 epochs before reducing
# plateau_min_lr: 1e-6
# warmup_epochs: 30        # Warmup 30 epochs
# Monitor: eval.val.rmsle (already configured)

# Training stability
gradient_clip_val: 1.0  # Gradient clipping value (clip gradients to prevent explosion)

# TIP Loss Parameters (not used in fine-tuning, but required by run.py)
corruption_rate: 0.0  # Not used during fine-tuning
temperature: 0.1  # Not used during fine-tuning
replace_special_rate: 0.0  # Not used during fine-tuning
check_val_every_n_epoch: 1
val_check_interval: 1.0  # Check validation every epoch
eval_metric: rmsle  # Metric to monitor for best checkpoint (rmsle, mae, rmse) - rmsle is primary
limit_train_batches: null  # Use all training batches
limit_val_batches: null  # Use all validation batches

# Early Stopping Configuration
use_early_stopping: true  # Enable/disable early stopping
early_stopping_patience: 20  # Number of epochs to wait before stopping (will be multiplied by 1/val_check_interval)
early_stopping_min_delta: 0.0002  # Minimum change to qualify as an improvement
limit_test_batches: null  # Use all test batches
gpus: 1
num_workers: 4
pin_memory: true
seed: 42
resume_training: false
test_and_eval: false  # Set to true to run test set evaluation after training

# Image
img_size: 224
eval_train_augment_rate: 0.0  # No augmentation for fine-tuning
live_loading: false
augmentation_speedup: true
eval_one_hot: false
delete_segmentation: false

# Satellite-specific
use_sentinel2: true
use_viirs: true

# Training Mode Flags
pretrain: false  # Set to true for pretraining
finetune: true   # Set to true for fine-tuning (construction cost specific)
evaluate: false  # Set to true for generic evaluation/fine-tuning (other tasks)
test: false     # Set to true for testing
generate_embeddings: false  # Set to true to generate embeddings only

# Logging
wandb_project: construction_cost_tip  # WandB project name (groups all experiments)
wandb_name: tip_finetune  # Legacy parameter (not used in current code)
use_wandb: true  # Enable WandB online logging
offline: false  # Set to false for online WandB logging
wandb_entity: null  # Set to your WandB entity/username if needed
wandb_id: null  # For resuming training
exp_name: tip_finetune_${regression_head.type}  # WandB experiment name (will have timestamp added in code): tip_finetune_QueryAttentionRegression_1221_0245
comment: "TIP fine-tuning for construction cost regression (frozen backbone)"

# Automatic Evaluation (runs after fine-tuning completes)
evaluator:
  enabled: true  # Set to true to automatically run evaluation after fine-tuning
  checkpoint_type: best  # Options: "best" or "last" - which checkpoint to use for evaluation
  val_csv: /hdd/hiep/CODE/Construction_Cost_Prediction/data/annotation/val/val_clean.csv
  test_csv: /hdd/hiep/CODE/Construction_Cost_Prediction/data/annotation/test/test_clean.csv
  composite_dir_trainval: /hdd/hiep/CODE/Construction_Cost_Prediction/data/trainval_composite
  composite_dir_test: /hdd/hiep/CODE/Construction_Cost_Prediction/data/test_composite
  field_lengths: /hdd/hiep/CODE/Construction_Cost_Prediction/data/annotation/field_lengths.pt
  val_metadata: /hdd/hiep/CODE/Construction_Cost_Prediction/data/annotation/val/val_clean_metadata.pkl
  test_metadata: /hdd/hiep/CODE/Construction_Cost_Prediction/data/annotation/test/test_clean_metadata.pkl
  batch_size: 32
  num_workers: 2
  device: cuda

