# Model Recommendations & Current Architecture

## Current Status: TIP (Tabular-Image Pre-training) âœ…

We are using **TIP (Tabular-Image Pre-training)**, a self-supervised pretraining framework for multimodal learning, adapted for construction cost regression.

### TIP Pretraining Pipeline (Two-Stage Training)

**Stage 1: Self-Supervised Pretraining**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           INPUT LAYER                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TABULAR MODALITY              â”‚  SATELLITE MODALITY                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”‚
â”‚  â€¢ Categorical: (B, 191)        â”‚  â€¢ Sentinel-2: (B, 9, H, W)                â”‚
â”‚  â€¢ Continuous: (B, 3)          â”‚  â€¢ VIIRS: (B, 3, H, W)                     â”‚
â”‚  â€¢ Total: 20 features          â”‚  â€¢ Combined: (B, 15, H, W)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  TABULAR ENCODER     â”‚      â”‚  IMAGE ENCODER          â”‚
        â”‚  TabularTransformer  â”‚      â”‚  SatelliteImageEncoder  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ - Embedding(191, 512)â”‚      â”‚ Sentinel-2:            â”‚
        â”‚ - Linear(1â†’512)     â”‚      â”‚ - Swin-v2-Base         â”‚
        â”‚ - Embedding(20, 512) â”‚      â”‚ - FPN (128D)           â”‚
        â”‚ Output: (B, 20, 512)â”‚      â”‚ - Proj: 128â†’512         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚                        â”‚
                    â”‚                 â”‚ VIIRS:                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚ - CNN: 3â†’64â†’256        â”‚
        â”‚ 4 x TransformerBlockâ”‚      â”‚ - Proj: 256â†’512         â”‚
        â”‚ - Masked Attention   â”‚      â”‚                        â”‚
        â”‚ - MLP: 512â†’2048â†’512  â”‚      â”‚ Combined: (B, 1024)    â”‚
        â”‚ Output: (B, 20, 512)â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
                    â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚ Projection Head         â”‚
        â”‚ SimCLRProjectionHead â”‚      â”‚ 1024â†’2048â†’128           â”‚
        â”‚ 512â†’512â†’128          â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
                    â”‚                               â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   MULTIMODAL ENCODER          â”‚
                    â”‚   MultimodalTransformer       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ - Image Proj: 1024â†’512        â”‚
                    â”‚ - Tabular: Identity (512)     â”‚
                    â”‚ - 4 x TransformerBlock        â”‚
                    â”‚   â€¢ Self-Attention            â”‚
                    â”‚   â€¢ Cross-Attention           â”‚
                    â”‚   â€¢ MLP: 512â†’2048â†’512         â”‚
                    â”‚ Output: (B, 20, 512)          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   TABULAR PREDICTOR            â”‚
                    â”‚   (for TR loss)               â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ - Cat: Linear(512â†’191)        â”‚
                    â”‚ - Con: Linear(512â†’1)          â”‚
                    â”‚ Output: Reconstructed featuresâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   THREE LOSSES                 â”‚
                    â”‚   â€¢ ITC: Contrastive (128D)  â”‚
                    â”‚   â€¢ ITM: Matching (512D)     â”‚
                    â”‚   â€¢ TR: Reconstruction        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Stage 2: Supervised Fine-Tuning**

- Load pretrained encoders (frozen or fine-tuned)
- Replace projection heads with regression head
- Train on log-transformed targets with Huber/MAE loss

### TIP Feature Shape Progression

| Stage | Module | Input Shape | Output Shape | Description |
|-------|--------|-------------|--------------|-------------|
| **Input** | - | - | - | Raw input data |
| | Tabular Categorical | - | `(B, 191)` | 191 categorical features (label encoded) |
| | Tabular Continuous | - | `(B, 3)` | 3 continuous features (normalized) |
| | Sentinel-2 | - | `(B, 9, H, W)` | 9 selected bands |
| | VIIRS | - | `(B, 3, H, W)` | 3 channels |
| **Tabular Encoding** | Embedding + Linear | `(B, 191)` + `(B, 3)` | `(B, 20, 512)` | Feature tokenization |
| | Transformer Blocks | `(B, 20, 512)` | `(B, 20, 512)` | 4 layers with masked attention |
| | Projection Head | `(B, 20, 512)` | `(B, 128)` | SimCLR projection |
| **Image Encoding** | Sentinel-2 Backbone | `(B, 9, H, W)` | `(B, 128)` | Swin-v2-Base + FPN |
| | VIIRS CNN | `(B, 3, H, W)` | `(B, 256)` | Lightweight CNN |
| | Projections | `(B, 128)` + `(B, 256)` | `(B, 1024)` | Concatenated and projected |
| | Projection Head | `(B, 1024)` | `(B, 128)` | SimCLR projection |
| **Multimodal Fusion** | Image Proj | `(B, 1024)` | `(B, 512)` | Linear projection |
| | Multimodal Transformer | `(B, 512)` + `(B, 512)` | `(B, 20, 512)` | 4 layers with cross-attention |
| **Pretraining Output** | ITC Loss | `(B, 128)` + `(B, 128)` | Scalar | Contrastive loss |
| | ITM Loss | `(B, 512)` | Scalar | Matching loss |
| | TR Loss | `(B, 512)` | Scalar | Reconstruction loss |
| **Fine-Tuning** | Regression Head | `(B, 512)` | `(B, 1)` | MLP for regression |

**Note:** `B` = batch size, `H` = image height (typically 224), `W` = image width (typically 224)

## TIP (Tabular-Image Pre-training) Integration âœ…

**Status:** Fully integrated and adapted for construction cost regression

**What:** Official TIP implementation (ECCV 2024) - Self-supervised pretraining framework for tabular + image multimodal learning.

**Location:** `src/models/TIP/` (cloned from https://github.com/siyi-wind/TIP)

### TIP Architecture Overview (Actual Implementation)

**Core Components:**

1. **Tabular Encoder** (`TabularTransformerEncoder`):
   - **Input Processing:**
     - Categorical features: `Embedding(191, 512)` - 191 categorical features with 512-dim embeddings
     - Continuous features: `Linear(1, 512)` - Projects each continuous feature to 512D
     - Column embeddings: `Embedding(20, 512)` - Positional embeddings for 20 total features
   - **Transformer Blocks:** 4 layers
     - Self-attention with **masked attention** (handles missing data)
     - QKV projection: `Linear(512â†’1536)`, output: `Linear(512â†’512)`
     - MLP: `512â†’2048â†’512` with GELU activation
     - LayerNorm and Dropout (0.1) for stability
   - **Projection Head:** `SimCLRProjectionHead`
     - `512â†’512â†’128` with BatchNorm and ReLU
   - **Output:** 128D contrastive embedding

2. **Image Encoder** (`SatelliteImageEncoder`):
   - **Sentinel-2 Backbone:** SatlasPretrain Swin-v2-Base
     - Input: 9 channels (selected from 12 Sentinel-2 bands)
     - Architecture: SwinTransformer with 4 stages
       - Stage 1: 128D (2 blocks)
       - Stage 2: 256D (2 blocks)
       - Stage 3: 512D (18 blocks)
       - Stage 4: 1024D (2 blocks)
     - **FPN (Feature Pyramid Network):** Multi-scale feature extraction
       - 4 levels: 128, 256, 512, 1024 â†’ all projected to 128D
       - Upsampling and fusion layers
     - Output: 128D feature maps
   - **VIIRS Encoder:** Lightweight CNN
     - `Conv2d(3, 64)` â†’ BatchNorm â†’ ReLU â†’ AdaptiveAvgPool â†’ `Linear(64â†’256)`
     - Output: 256D
   - **Projections:**
     - Sentinel-2: `Linear(128â†’512)`
     - VIIRS: `Linear(256â†’512)`
   - **Combined:** Concatenated to 1024D (512+512)
   - **Projection Head:** `SimCLRProjectionHead`
     - `1024â†’2048â†’128` with BatchNorm and ReLU
   - **Output:** 128D contrastive embedding

3. **Multimodal Encoder** (`MultimodalTransformerEncoder`):
   - **Input Projections:**
     - Image: `Linear(1024â†’512)` + LayerNorm
     - Tabular: Identity (already 512D)
   - **Transformer Blocks:** 4 layers
     - **Self-Attention:** Standard multi-head attention (512â†’1536â†’512)
     - **Cross-Attention:** Cross-modal attention between image and tabular
       - KV projection: `Linear(512â†’1024)` (from tabular)
       - Q projection: `Linear(512â†’512)` (from image)
       - Output: `Linear(512â†’512)`
     - MLP: `512â†’2048â†’512` with GELU
     - LayerNorm after each sub-layer
   - **Output:** 512D fused multimodal representation

4. **Tabular Predictor** (`TabularPredictor`):
   - **Categorical Reconstruction:** `Linear(512â†’191)` - Reconstructs 191 categorical features
   - **Continuous Reconstruction:** `Linear(512â†’1)` - Reconstructs continuous features
   - Used for **TR (Tabular Reconstruction)** loss during pretraining

### Three Loss Functions (from `TipModel3Loss.py`):

1. **ITC (Image-Tabular Contrastive)** - `CLIPLoss`:
   - CLIP-style contrastive learning
   - Maximizes similarity between matching image-tabular pairs
   - Minimizes similarity between non-matching pairs
   - Temperature-scaled cosine similarity

2. **ITM (Image-Tabular Matching)**:
   - Binary classification task
   - Predicts whether image-tabular pair matches
   - Uses hard negative mining (weighted sampling)

3. **TR (Tabular Reconstruction)** - `ReconstructionLoss`:
   - Reconstructs masked tabular features
   - Categorical: Cross-entropy loss
   - Continuous: MSE loss
   - Only computed on masked features

### Key Files:

- **Models:**
  - `models/Tips/TipModel3Loss.py` - Main TIP model with 3 losses (ITC, ITM, TR)
  - `models/Tip_utils/Tip_pretraining.py` - Base pretraining class
  - `models/Tip_utils/Tip_downstream.py` - Fine-tuning backbone (with regression head)
  - `models/Tip_utils/Transformer.py` - Tabular & Multimodal transformers
  - `models/Tip_utils/SatelliteImageEncoder.py` - **NEW**: SatlasPretrain integration
  - `models/Evaluator_ConstructionCost.py` - **NEW**: Regression fine-tuning module

- **Losses:**
  - `utils/clip_loss.py` - CLIP contrastive loss (ITC)
  - `utils/reconstruct_loss.py` - Tabular reconstruction loss (TR)

- **Datasets:**
  - `datasets/ConstructionCostTIPDataset.py` - **NEW**: Custom dataset for construction cost data
  - `datasets/ContrastiveReconstructImagingAndTabularDataset.py` - Original TIP dataset

- **Training:**
  - `run.py` - Main entry point (uses Hydra config)
  - `trainers/pretrain.py` - Pretraining script (adapted for construction cost)
  - `trainers/evaluate.py` - Fine-tuning/evaluation script (adapted for regression)

- **Preprocessing:**
  - `data/preprocess_construction_cost.py` - **NEW**: Tabular data preprocessing
  - `utils/generate_field_lengths.py` - **NEW**: Generates field_lengths.pt

- **Evaluation:**
  - `utils/ssl_online_regression.py` - **NEW**: Online regression evaluation during pretraining

- **Configuration:**
  - `configs/config_construction_cost_pretrain.yaml` - **NEW**: Pretraining config
  - `configs/config_construction_cost_finetune.yaml` - **NEW**: Fine-tuning config

### Configuration (from `configs/config_construction_cost_pretrain.yaml`):

- **Architecture:**
  - `tabular_embedding_dim`: 512
  - `multimodal_embedding_dim`: 512
  - `tabular_transformer_num_layers`: 4
  - `multimodal_transformer_num_layers`: 4
  - `projection_dim`: 128
  - `num_cat`: 191 (categorical features)
  - `num_con`: 3 (continuous features)
  - `image_encoder_output_dim`: 1024 (Sentinel-2 + VIIRS combined)

- **Training:**
  - `temperature`: 0.1 (for contrastive loss)
  - `corruption_rate`: 0.3 (tabular masking rate)
  - `replace_random_rate`: 0.15 (random replacement)
  - `replace_special_rate`: 0.50 (special token replacement)
  - `batch_size`: 32 (configurable)
  - `lr`: 3e-4
  - `target_log_transform`: True (log-transform construction cost)
  - `online_mlp`: True (online regression evaluation during pretraining)

### Why TIP Helps This Regression Task:

1. **Cross-Modal Alignment**: ITC loss aligns tabular and satellite embeddings
2. **Robustness to Missing Data**: TR loss + masking handles incomplete features
3. **Better Representations**: Multimodal encoder learns joint representations
4. **Transfer Learning**: Pretrained encoders provide better initialization

### Implementation Status:

âœ… **Completed:**

1. **Dataset Adaptation** (`ConstructionCostTIPDataset`):
   - Loads Sentinel-2 (12 bands) and VIIRS (1 band) images
   - Concatenates to 15-channel input, selects 9 bands for Sentinel-2
   - Processes tabular data: 191 categorical + 3 continuous features
   - Supports masking for TR loss
   - Handles log-transformed targets
   - Uses preprocessing metadata for consistent encoding

2. **Model Adaptation**:
   - âœ… `SatelliteImageEncoder`: Integrates SatlasPretrain Swin-v2-Base + FPN
   - âœ… `TabularTransformerEncoder`: Uses masked attention for missing data
   - âœ… `MultimodalTransformerEncoder`: Cross-attention fusion
   - âœ… `TabularPredictor`: Reconstruction heads for TR loss

3. **Training Pipeline**:
   - âœ… Stage 1: TIP pretraining (`trainers/pretrain.py`)
     - ITC (Image-Tabular Contrastive) loss
     - ITM (Image-Tabular Matching) loss
     - TR (Tabular Reconstruction) loss
     - Online regression evaluation during pretraining
   - âœ… Stage 2: Fine-tuning (`trainers/evaluate.py`)
     - Regression head with Huber/MAE loss
     - RMSLE as primary metric
     - Supports freezing/unfreezing image backbone

4. **Preprocessing** (`preprocess_construction_cost.py`):
   - Generates clean CSVs with consistent encoding
   - Saves metadata (encoders, normalization stats)
   - Union cardinality strategy for categorical features
   - Handles train/val/test splits

### Key Features:

- **Masked Attention**: TabularTransformerEncoder uses masked attention to handle missing/incomplete tabular features
- **Multi-Scale Features**: FPN extracts features at multiple scales from Sentinel-2
- **Cross-Modal Alignment**: ITC loss aligns satellite and tabular embeddings in shared space
- **Robustness**: TR loss + masking improves model robustness to missing data
- **Online Evaluation**: Regression metrics (MAE, RMSE, RMSLE, RÂ²) computed during pretraining

### References:
- **GitHub:** https://github.com/siyi-wind/TIP
- **Paper:** https://arxiv.org/abs/2407.07582
- **ECCV 2024:** Tabular-Image Pre-training for Multimodal Classification with Incomplete Data

---

## Multi-Task Head Architecture (Country-Aware Regression) ğŸ†•

### Problem Statement

The construction cost data shows a **bimodal distribution** driven by **country** (0 and 1). Each country has different target statistics:
- **Country 0**: mean=7.478149, std=0.138897 (higher cost pattern)
- **Country 1**: mean=5.304986, std=0.283889 (lower cost pattern)

**Goal**: Build a multi-task head that:
1. **Classifies** which country the sample belongs to
2. **Uses country-specific normalization** (target_mean, target_std) for regression
3. **Calculates regression loss** using the appropriate country's statistics

### Configuration

Added to `config_construction_cost_pretrain.yaml` and `config_construction_cost_finetune.yaml`:

```yaml
regression_head:
  # Multi-task head configuration
  multi_head: false  # If true, use country-aware multi-task head (classification + regression)
                     # If false, use single head with overall normalization (backward compatible)
  
  # Overall target statistics (used when multi_head=false or as fallback)
  target_mean: 6.513477  # Mean of log(1 + target) values (overall)
  target_std: 1.101045   # Std of log(1 + target) values (overall)
  target_log_transform: true
  
  # Country-specific target statistics (used when multi_head=true)
  # Format: {country_id: value} where country_id is 0 or 1
  target_mean_by_country:
    0: 7.478149  # Mean of log(1 + target) for country 0
    1: 5.304986  # Mean of log(1 + target) for country 1
  target_std_by_country:
    0: 0.138897  # Std of log(1 + target) for country 0
    1: 0.283889  # Std of log(1 + target) for country 1
```

### Recommended Architecture: Parallel Branches

```
Input: (B, N, n_input) multimodal features from TIP backbone
  â†“
Shared Feature Aggregation (Mean Pooling or Attention)
  â†“ (B, n_input)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Country Branch      â”‚ Regression Branch     â”‚
â”‚ (Classification)    â”‚ (Regression)         â”‚
â”‚                     â”‚                      â”‚
â”‚ MLP â†’ (B, 2) logitsâ”‚ MLP â†’ (B, 1) pred   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“                    â†“
Country Loss      Regression Loss
(CrossEntropy)    (RMSLE with country-specific normalization)
```

**Key Design:**
- **Shared backbone**: Mean pooling or attention to aggregate (B, N, n_input) â†’ (B, n_input)
- **Country branch**: MLP â†’ (B, 2) logits for binary classification
- **Regression branch**: MLP â†’ (B, 1) prediction in log space
- **Loss calculation**:
  - Country loss: CrossEntropyLoss
  - Regression loss: RMSLE using **ground truth country's** target_mean/std (avoids dependency on classification accuracy)
- **Total loss**: `total_loss = 0.1 * country_loss + 1.0 * regression_loss`

**Implementation Status:**
- âœ… Config updated with `multi_head` flag and country-specific stats
- â³ Head implementation pending (waiting for user confirmation)

### Preprocessing Updates

The preprocessing script (`src/data/preprocess_construction_cost.py`) now:
- Calculates country-specific `target_mean` and `target_std` for each country
- Saves these in metadata as `target_stats_by_country`
- Prints country-specific stats for config
- Updated visualization to show country-specific distributions overlaid on overall distribution

**Country Statistics (from validation set):**
- Country 0: mean=7.478149, std=0.138897, n_samples=114
- Country 1: mean=5.304986, std=0.283889, n_samples=91

---

## References

- **TIP (Tabular-Image Pre-training):** [GitHub](https://github.com/siyi-wind/TIP) | [Paper](https://arxiv.org/abs/2407.07582) | ECCV 2024
- **SatlasPretrain:** [GitHub](https://github.com/allenai/satlaspretrain_models) | [Paper](https://arxiv.org/abs/2306.15464)
